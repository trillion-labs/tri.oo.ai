# tri.oo.ai

**tri.oo.ai** is a local, open-source showcase of what you can build with **[Tri-7B-Search](https://huggingface.co/trillionlabs/Tri-7B-Search-preview)**, an efficient LLM with search capabilities ğŸ’š. It brings a familiar chat-based interface â€” inspired by [oo.ai](https://oo.ai).

## ğŸ” What is tri.oo.ai?

tri.oo.ai replicates the functionality of oo.ai with a local-first approach and open tooling. It uses the **Tri-7B-Search** model as the engine behind a smart assistant that can:

* Understand natural queries
* Retrieve relevant data from your knowledge base
* Augment answers with **DuckDuckGo search results**
* Run locally for full control and privacy

This is a **search-enabled LLM service** â€” combining the reasoning of LLMs with the freshness of web search.


## ğŸ’¡ Example

> í˜ì´ì»¤ ì¬ê³„ì•½ ì†Œì‹


í˜ì´ì»¤(ì´ìƒí˜)ëŠ” **2029ë…„ê¹Œì§€ T1ê³¼ 4ë…„ ì¬ê³„ì•½**ì„ ì²´ê²°í•œ ì‚¬ì‹¤ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” 2025ë…„ 7ì›” 27ì¼(2025ë…„ ê¸°ì¤€) ê³µì‹ ë°œí‘œëœ ë‚´ìš©ìœ¼ë¡œ, ë¦¬ê·¸ ì˜¤ë¸Œ ë ˆì „ë“œ(LoL) eìŠ¤í¬ì¸  ì—­ì‚¬ìƒ ìµœì´ˆë¡œ **18ì‹œì¦Œ ì—°ì† í™œë™**ì„ ì´ì–´ê°€ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ìš” ê³„ì•½ ì¡°ê±´ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
- **ê³„ì•½ ê¸°ê°„**: 2025ë…„ 7ì›” 27ì¼ë¶€í„° **2029ë…„ 6ì›” 30ì¼ê¹Œì§€** (4ë…„ê°„)
- **ì„±ê³¼**: í•´ë‹¹ ê¸°ê°„ ë™ì•ˆ **2022 LCK ìŠ¤í”„ë§ ì „ìŠ¹ ìš°ìŠ¹**, **2023 ì•„ì‹œì•ˆê²Œì„ ê¸ˆë©”ë‹¬**, **2023Â·2024 LoL ì›”ë“œ ì±”í”¼ì–¸ì‹­ 2ì—°íŒ¨** ë“± ì—­ëŒ€ ìµœê³  ìˆ˜ì¤€ì˜ ì„±ì ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.
- **ì˜ë¯¸**: í˜ì´ì»¤ëŠ” 2013ë…„ ë°ë·” ì´ë˜ **íŒ€ì˜ ìƒì§•**ìœ¼ë¡œ í™œì•½í•˜ë©° eìŠ¤í¬ì¸  ì—­ì‚¬ì— í•œ íšì„ ê·¸ì€ ì„ ìˆ˜ë¡œ í‰ê°€ë°›ê³  ìˆìŠµë‹ˆë‹¤.

**ì¶œì²˜**
1. [ì¡°ì„ ë¹„ì¦ˆ] [í˜ì´ì»¤ ì´ìƒí˜, T1ê³¼ 4ë…„ ì¬ê³„ì•½ ë°œí‘œ](https://www.chosun.com/sports/sports_general/2025/07/27/VOQ3LGJWPFBX7DKGXD5ESQBTZQ/)  
2. [ì—°í•©ë‰´ìŠ¤] [í˜ì´ì»¤ ì´ìƒí˜, 2029ë…„ê¹Œì§€ ë›´ë‹¤â€¦T1ê³¼ 4ë…„ ì¬ê³„ì•½](https://www.yna.co.kr/view/AKR20250727045800017)  
3. [ê²Œì„ë·°] [í˜ì´ì»¤ ì´ìƒí˜, T1ê³¼ 4ë…„ ì¬ê³„ì•½ ë°œí‘œ '2029ë…„ê¹Œì§€ ë™í–‰'](https://www.gamevu.co.kr/news/articleView.html?idxno=50414)


## Installation

1. Clone the repository:
```bash
git clone https://github.com/trillion-labs/tri.oo.ai.git
cd tri.oo.ai
```

2. Install UV (if not already installed):
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

3. Create virtual environment and install dependencies:
```bash
uv sync

# for offline vllm usage
uv sync --group vllm
```

## Usage

### Option 1: Direct vLLM Usage

Run the interactive assistant with direct vLLM integration:

```bash
uv run main.py
```

Command line options:
- `--model`: Model name or path (default: "trillionlabs/Tri-7B-Search-preview")
- `--tensor-parallel-size`: Number of GPUs for tensor parallelism (default: 1)
- `--gpu-memory-utilization`: GPU memory utilization 0-1 (default: 0.9)

Example:
```bash
uv run main.py --tensor-parallel-size 2 --gpu-memory-utilization 0.8
```

### Option 2: OpenAI-Compatible API

For better flexibility and integration, you can use the OpenAI-compatible API:

1. Start the vLLM server:
```bash
./serve.sh
```

This will start a vLLM server at `http://localhost:8000` with the Tri-7B-Search-preview model.

2. In a new terminal, run the API client:
```bash
uv run main_api.py
```

Command line options for the API client:
- `--base-url`: Base URL for the OpenAI-compatible API (default: "http://localhost:8000/v1")
- `--model`: Model name (default: "trillionlabs/Tri-7B-Search-preview")

Example with custom server:
```bash
python main_api.py --base-url "http://your-server:8080/v1"
```

### Which Option to Choose?

- **Direct vLLM (`main.py`)**: Best for single-user local usage with minimal setup
- **API mode (`main_api.py`)**: Best for multi-user scenarios, integration with other tools, or when you want to separate the model server from the client

This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- Powered by [vLLM](https://github.com/vllm-project/vllm) for efficient inference
- Web search functionality via [DuckDuckGo Search](https://github.com/deedy5/duckduckgo_search)